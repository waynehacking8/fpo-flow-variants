%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NeurIPS-style Poster for Overleaf
% A0 Portrait
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[a0paper,portrait]{tikzposter}

%-----------------------------------------------------------
% Packages
%-----------------------------------------------------------
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{xcolor}

%-----------------------------------------------------------
% Theme & Colors
%-----------------------------------------------------------
\usetheme{Default}

\definecolor{neuripsblue}{RGB}{0, 51, 102}
\definecolor{neuripsred}{RGB}{180, 50, 50}
\definecolor{neuripsgreen}{RGB}{34, 139, 34}
\definecolor{lightyellow}{RGB}{255, 250, 230}
\definecolor{lightgreen}{RGB}{230, 250, 230}
\definecolor{lightred}{RGB}{255, 235, 235}
\definecolor{lightblue}{RGB}{230, 240, 250}

% Custom color style
\definecolorstyle{NeurIPS}{
    \definecolor{colorOne}{RGB}{0, 51, 102}
    \definecolor{colorTwo}{RGB}{230, 230, 230}
    \definecolor{colorThree}{RGB}{255, 255, 255}
}{
    \colorlet{backgroundcolor}{white}
    \colorlet{framecolor}{colorOne}
    \colorlet{titlefgcolor}{white}
    \colorlet{titlebgcolor}{colorOne}
    \colorlet{blocktitlebgcolor}{colorOne}
    \colorlet{blocktitlefgcolor}{white}
    \colorlet{blockbodybgcolor}{white}
    \colorlet{blockbodyfgcolor}{black}
}
\usecolorstyle{NeurIPS}

%-----------------------------------------------------------
% Title
%-----------------------------------------------------------
\title{\textbf{Comparative Analysis of Flow Schedules in\\Flow Policy Optimization for Robot Learning}}
\author{Wei-Cheng Chiu, Shang-Yen Lee, Yu-Tang Chang, Li-Chen Kao}
\institute{National Taiwan University, Department of CSIE}

%-----------------------------------------------------------
% Document
%-----------------------------------------------------------
\begin{document}
\maketitle

\begin{columns}

%=========================================================
% LEFT COLUMN
%=========================================================
\column{0.33}

%-----------------------------------------------------------
% Motivation
%-----------------------------------------------------------
\block{1. Motivation \& Research Question}{
    \textbf{Flow Policy Optimization (FPO)} replaces Gaussian policies with flow-based generative models for reinforcement learning.

    \vspace{0.8cm}

    \textbf{The Problem:} Original FPO uses Optimal Transport (OT) schedule, but \textcolor{neuripsred}{\textbf{never compared}} with other schedules from generative modeling:

    \begin{itemize}[leftmargin=*]
        \item Variance Preserving (VP) -- from DDPM
        \item Variance Exploding (VE) -- from Score SDE
        \item Cosine -- from Improved DDPM
    \end{itemize}

    \vspace{0.8cm}

    \innerblock[]{Research Question}{
        \centering\Large
        Which flow schedule works best\\for reinforcement learning? Why?
    }
}

%-----------------------------------------------------------
% Method
%-----------------------------------------------------------
\block{2. Flow Schedules Compared}{
    Flow matching interpolates noise $x_0$ to action $x_1$:
    \begin{equation*}
    x_t = \alpha_t \cdot x_1 + \sigma_t \cdot x_0
    \end{equation*}

    \vspace{0.5cm}

    \renewcommand{\arraystretch}{1.8}
    \begin{tabular}{@{}p{4cm}p{5cm}p{4.5cm}@{}}
    \toprule
    \textbf{Schedule} & \textbf{Coefficients} & \textbf{Path} \\
    \midrule
    \rowcolor{lightgreen}
    \textbf{OT (Ours)} & $\alpha_t = 1-t,\ \sigma_t = t$ & \textbf{Straight line} \\
    VP & $\alpha_t = \cos(\frac{\pi t}{2})$ & Curved \\
    Cosine & $\alpha_t = \cos^2(\frac{\pi t}{2})$ & Curved \\
    \rowcolor{lightred}
    VE & $\sigma_t = 0.01 \cdot 8000^t$ & \textbf{Explosive!} \\
    \bottomrule
    \end{tabular}

    \vspace{0.8cm}

    \textbf{Key Insight:} OT has \textcolor{neuripsgreen}{\textbf{constant}} velocity target $v = x_1 - x_0$, while others have \textbf{time-varying} targets $\rightarrow$ harder to learn.
}

%-----------------------------------------------------------
% Environments
%-----------------------------------------------------------
\block{3. Experimental Setup}{
    \textbf{4 Robot Control Tasks} (IsaacGym / MJX):

    \vspace{0.5cm}

    \renewcommand{\arraystretch}{1.6}
    \begin{tabular}{@{}p{5.5cm}cc@{}}
    \toprule
    \textbf{Environment} & \textbf{Act Dim} & \textbf{Type} \\
    \midrule
    HumanoidGetup & 21 & Goal-directed \\
    Go1 Getup & 12 & Goal-directed \\
    Go1 Joystick & 12 & Tracking \\
    \rowcolor{lightyellow}
    Go1 Handstand & 12 & \textbf{Multimodal} \\
    \bottomrule
    \end{tabular}

    \vspace{0.5cm}

    \textbf{Training:} 10M timesteps, 2048 parallel environments

    \textbf{Framework:} JAX / Brax / MJX
}

%=========================================================
% MIDDLE COLUMN
%=========================================================
\column{0.34}

%-----------------------------------------------------------
% Main Results
%-----------------------------------------------------------
\block{4. Main Results: OT Wins All Tasks}{
    % ====== 图片1: final_performance_comparison.png ======
    \begin{center}
    \includegraphics[width=0.95\linewidth]{figures/final_performance_comparison.png}
    \end{center}

    \vspace{0.3cm}

    \innerblock[]{}{
        \centering\large
        \textcolor{neuripsgreen}{\textbf{OT outperforms VP by +2\% to +183\%}}\\
        (largest gap in multimodal Handstand task)
    }

    \vspace{0.5cm}

    \textbf{Normalized Performance Heatmap:}

    % ====== 图片2: performance_heatmap.png ======
    \begin{center}
    \includegraphics[width=0.85\linewidth]{figures/performance_heatmap.png}
    \end{center}

    \vspace{0.3cm}

    \renewcommand{\arraystretch}{1.5}
    \begin{tabular}{@{}lccc@{}}
    \toprule
    \textbf{Task} & \textbf{OT} & \textbf{VP} & \textbf{Cosine} \\
    \midrule
    HumanoidGetup & \cellcolor{lightgreen}100\% & 97.7\% & 98.0\% \\
    Go1 Getup & \cellcolor{lightgreen}100\% & \cellcolor{lightred}47.4\% & 54.8\% \\
    Go1 Joystick & \cellcolor{lightgreen}100\% & 91.1\% & 80.0\% \\
    Go1 Handstand & \cellcolor{lightgreen}100\% & \cellcolor{lightred}35.3\% & 41.0\% \\
    \bottomrule
    \end{tabular}
}

%-----------------------------------------------------------
% VE Failure
%-----------------------------------------------------------
\block{5. Why Variance Exploding (VE) Fails}{
    \textbf{\textcolor{neuripsred}{VE produced NaN in 100\% of experiments!}}

    \vspace{0.3cm}

    % ====== 图片3: ve_failure_comprehensive.png ======
    \begin{center}
    \includegraphics[width=0.92\linewidth]{figures/ve_failure_comprehensive.png}
    \end{center}

    \vspace{0.3cm}

    \textbf{Root Cause: Gradient Explosion}
    \begin{equation*}
    \frac{d\sigma}{dt}\bigg|_{t=1} = 80 \times \ln(8000) \approx \textcolor{neuripsred}{\mathbf{719}}
    \end{equation*}

    \vspace{0.3cm}

    \begin{itemize}[leftmargin=*]
        \item RL actions are bounded: $a \in [-1, 1]$
        \item VE velocity target magnitude: $\|v\| \approx 700$
        \item $\Rightarrow$ \textbf{Massive scale mismatch causes NaN}
    \end{itemize}

    \vspace{0.3cm}

    \innerblock[]{Conclusion}{
        \centering
        VE is \textbf{fundamentally incompatible}\\with bounded action spaces in RL
    }
}

%=========================================================
% RIGHT COLUMN
%=========================================================
\column{0.33}

%-----------------------------------------------------------
% FPO vs PPO
%-----------------------------------------------------------
\block{6. FPO vs PPO: Task-Dependent}{
    % ====== 图片4: fpo_vs_ppo_summary.png ======
    \begin{center}
    \includegraphics[width=0.95\linewidth]{figures/fpo_vs_ppo_summary.png}
    \end{center}

    \vspace{0.3cm}

    \renewcommand{\arraystretch}{1.6}
    \begin{tabular}{@{}p{5cm}rrr@{}}
    \toprule
    \textbf{Task} & \textbf{FPO-OT} & \textbf{PPO} & \textbf{$\Delta$} \\
    \midrule
    HumanoidGetup & 4201.9 & 2910.0 & \cellcolor{lightgreen}\textbf{+44\%} \\
    Go1 Getup & 18.29 & 12.50 & \cellcolor{lightgreen}\textbf{+46\%} \\
    Go1 Handstand & 3.34 & 1.78 & \cellcolor{lightgreen}\textbf{+87\%} \\
    Go1 Joystick & 4.39 & 16.94 & \cellcolor{lightred}\textbf{-74\%} \\
    \bottomrule
    \end{tabular}

    \vspace{0.5cm}

    \innerblock[]{Key Finding}{
        \centering
        \textbf{Multimodal tasks} $\rightarrow$ FPO wins \textbf{(+87\%)}\\[0.2cm]
        \textbf{Unimodal tracking} $\rightarrow$ PPO wins \textbf{(+285\%)}
    }
}

%-----------------------------------------------------------
% Multimodality Analysis
%-----------------------------------------------------------
\block{7. Why FPO Excels at Multimodal Tasks}{
    \textbf{Go1 Handstand:} Robot can flip \textcolor{blue}{\textbf{LEFT}} or \textcolor{red}{\textbf{RIGHT}} — both valid!

    \vspace{0.3cm}

    % ====== 图片5: go1_handstand_multimodal_explanation.png ======
    \begin{center}
    \includegraphics[width=0.95\linewidth]{figures/go1_handstand_multimodal_explanation.png}
    \end{center}

    \vspace{0.3cm}

    \textbf{The Mode-Averaging Problem:}

    \begin{itemize}[leftmargin=*]
        \item \textbf{PPO} (Gaussian): Averages both modes $\rightarrow$ outputs \textbf{zero} $\rightarrow$ robot doesn't flip $\rightarrow$ \textcolor{neuripsred}{\textbf{FAILS}}
        \vspace{0.2cm}
        \item \textbf{FPO} (Flow): Captures both peaks $\rightarrow$ samples one valid action $\rightarrow$ \textcolor{neuripsgreen}{\textbf{SUCCEEDS}}
    \end{itemize}
}

%-----------------------------------------------------------
% Conclusions
%-----------------------------------------------------------
\block{8. Conclusions \& Recommendations}{
    \begin{enumerate}[leftmargin=*,label=\textbf{\arabic*.}]
        \item \textcolor{neuripsgreen}{\textbf{Use Optimal Transport (OT)}} for flow-based RL
        \begin{itemize}
            \item Constant velocity target $\rightarrow$ simplest regression
            \item Straight path $\rightarrow$ shortest trajectory
            \item \textbf{Best performance across ALL tasks}
        \end{itemize}

        \vspace{0.4cm}

        \item \textcolor{neuripsred}{\textbf{Avoid Variance Exploding (VE)}} in RL
        \begin{itemize}
            \item $\sigma_{max}=80$ causes gradient explosion
            \item Fundamentally incompatible with bounded actions
        \end{itemize}

        \vspace{0.4cm}

        \item \textbf{Choose algorithm based on task structure}
        \begin{itemize}
            \item Multimodal tasks $\rightarrow$ FPO (up to +87\%)
            \item Unimodal tasks $\rightarrow$ PPO (more efficient)
        \end{itemize}
    \end{enumerate}

    \vspace{0.5cm}

    \innerblock[]{Take-Home Message}{
        \centering\Large
        Flow schedules designed for image generation\\
        \textbf{do not transfer directly} to robot learning.\\[0.3cm]
        \textbf{Optimal Transport is the gold standard for FPO.}
    }
}

\end{columns}

\end{document}
